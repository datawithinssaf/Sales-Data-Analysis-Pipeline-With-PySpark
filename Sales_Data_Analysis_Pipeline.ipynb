{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the Dataset from Kaggle**"
      ],
      "metadata": {
        "id": "WjZbSp0V7cym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we connect Google Drive to access the Kaggle API token stored inside it.  \n",
        "Using the Kaggle API, we import the **Superstore Sales Dataset**, which is a retail dataset of a global superstore collected over four years.  \n",
        "After downloading, we unzip the dataset files so that we can start exploring and analyzing them with PySpark."
      ],
      "metadata": {
        "id": "I2cn6iPL8baU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDB1b2Me22as",
        "outputId": "eeec5b33-46a6-41bf-bcd2-b4d5394d1b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IUnGfIB-68nA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rohitsahoo/sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAy3-ced7HtK",
        "outputId": "213765e8-0c11-4852-9374-21bef9b894f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting\n",
            "License(s): GPL-2.0\n",
            "Downloading sales-forecasting.zip to /content\n",
            "  0% 0.00/480k [00:00<?, ?B/s]\n",
            "100% 480k/480k [00:00<00:00, 1.42GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o sales-forecasting.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXl1n92g7hy2",
        "outputId": "3cc4858b-60a7-45cb-c065-8c6fb7bf5db4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sales-forecasting.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading CSV File**"
      ],
      "metadata": {
        "id": "i9NbV0-x8paF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"SalesAnalysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "R5C7mMPu8sW9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset path\n",
        "path = \"/content/train.csv\"\n",
        "\n",
        "# Read the CSV file into a Spark DataFrame\n",
        "df = spark.read.csv(path, header=True, inferSchema=True)\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik1sOIoX-CpY",
        "outputId": "f27f1efb-b659-4ac5-ce1e-82f5d0a0769d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+--------+\n",
            "|Row ID|      Order ID|Order Date| Ship Date|     Ship Mode|Customer ID|  Customer Name|  Segment|      Country|           City|     State|Postal Code|Region|     Product ID|       Category|Sub-Category|        Product Name|   Sales|\n",
            "+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+--------+\n",
            "|     1|CA-2017-152156|08/11/2017|11/11/2017|  Second Class|   CG-12520|    Claire Gute| Consumer|United States|      Henderson|  Kentucky|      42420| South|FUR-BO-10001798|      Furniture|   Bookcases|Bush Somerset Col...|  261.96|\n",
            "|     2|CA-2017-152156|08/11/2017|11/11/2017|  Second Class|   CG-12520|    Claire Gute| Consumer|United States|      Henderson|  Kentucky|      42420| South|FUR-CH-10000454|      Furniture|      Chairs|Hon Deluxe Fabric...|  731.94|\n",
            "|     3|CA-2017-138688|12/06/2017|16/06/2017|  Second Class|   DV-13045|Darrin Van Huff|Corporate|United States|    Los Angeles|California|      90036|  West|OFF-LA-10000240|Office Supplies|      Labels|Self-Adhesive Add...|   14.62|\n",
            "|     4|US-2016-108966|11/10/2016|18/10/2016|Standard Class|   SO-20335| Sean O'Donnell| Consumer|United States|Fort Lauderdale|   Florida|      33311| South|FUR-TA-10000577|      Furniture|      Tables|Bretford CR4500 S...|957.5775|\n",
            "|     5|US-2016-108966|11/10/2016|18/10/2016|Standard Class|   SO-20335| Sean O'Donnell| Consumer|United States|Fort Lauderdale|   Florida|      33311| South|OFF-ST-10000760|Office Supplies|     Storage|Eldon Fold 'N Rol...|  22.368|\n",
            "+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rows\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-w4JXtDOw1u",
        "outputId": "cdfdd024-b617-4741-e7e6-5bb6397387a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9800"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see basic statistics of numeric columns\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-iACAm6bgLa",
        "outputId": "d4d4b775-9dcb-4ff1-fd87-5cda08955d32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+--------------+--------------+-----------+------------------+-----------+-------------+--------+-------+------------------+-------+---------------+----------+------------+--------------------+-----------------+\n",
            "|summary|            Row ID|      Order ID|     Ship Mode|Customer ID|     Customer Name|    Segment|      Country|    City|  State|       Postal Code| Region|     Product ID|  Category|Sub-Category|        Product Name|            Sales|\n",
            "+-------+------------------+--------------+--------------+-----------+------------------+-----------+-------------+--------+-------+------------------+-------+---------------+----------+------------+--------------------+-----------------+\n",
            "|  count|              9800|          9800|          9800|       9800|              9800|       9800|         9800|    9800|   9800|              9789|   9800|           9800|      9800|        9800|                9800|             9508|\n",
            "|   mean|            4900.5|          NULL|          NULL|       NULL|              NULL|       NULL|         NULL|    NULL|   NULL|55273.322402696904|   NULL|           NULL|      NULL|        NULL|                NULL|235.2895627576727|\n",
            "| stddev|2829.1606529145706|          NULL|          NULL|       NULL|              NULL|       NULL|         NULL|    NULL|   NULL|32041.223412813004|   NULL|           NULL|      NULL|        NULL|                NULL| 635.178384045279|\n",
            "|    min|                 1|CA-2015-100006|   First Class|   AA-10315|     Aaron Bergman|   Consumer|United States|Aberdeen|Alabama|              1040|Central|FUR-BO-10000112| Furniture| Accessories|\"\"\"While you Were...|            0.444|\n",
            "|    max|              9800|US-2018-169551|Standard Class|   ZD-21925|Zuschuss Donatelli|Home Office|United States|    Yuma|Wyoming|             99301|   West|TEC-PH-10004977|Technology|      Tables|netTALK DUO VoIP ...|         22638.48|\n",
            "+-------+------------------+--------------+--------------+-----------+------------------+-----------+-------------+--------+-------+------------------+-------+---------------+----------+------------+--------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the schema (structure) of the DataFrame\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdXDtJRb-JNf",
        "outputId": "6d472188-ba1e-4864-c9ac-6ccb3ce14c4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Row ID: integer (nullable = true)\n",
            " |-- Order ID: string (nullable = true)\n",
            " |-- Order Date: string (nullable = true)\n",
            " |-- Ship Date: string (nullable = true)\n",
            " |-- Ship Mode: string (nullable = true)\n",
            " |-- Customer ID: string (nullable = true)\n",
            " |-- Customer Name: string (nullable = true)\n",
            " |-- Segment: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- Postal Code: integer (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Product ID: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Sub-Category: string (nullable = true)\n",
            " |-- Product Name: string (nullable = true)\n",
            " |-- Sales: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names with their data types\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng2ocr4B-KpN",
        "outputId": "c4b4e371-3b2c-488d-ed66-8e4f1b550085"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Row ID', 'int'),\n",
              " ('Order ID', 'string'),\n",
              " ('Order Date', 'string'),\n",
              " ('Ship Date', 'string'),\n",
              " ('Ship Mode', 'string'),\n",
              " ('Customer ID', 'string'),\n",
              " ('Customer Name', 'string'),\n",
              " ('Segment', 'string'),\n",
              " ('Country', 'string'),\n",
              " ('City', 'string'),\n",
              " ('State', 'string'),\n",
              " ('Postal Code', 'int'),\n",
              " ('Region', 'string'),\n",
              " ('Product ID', 'string'),\n",
              " ('Category', 'string'),\n",
              " ('Sub-Category', 'string'),\n",
              " ('Product Name', 'string'),\n",
              " ('Sales', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Segment** column has 3 unique values: *Consumer*, *Corporate*, and *Home Office*.\n",
        "\n",
        "- **Consumer**: individual buyers purchasing products for personal use.  \n",
        "- **Corporate**: businesses or companies purchasing in bulk for their offices or employees.  \n",
        "- **Home Office**: small or self-employed individuals running a business from home, such as freelancers or small startups."
      ],
      "metadata": {
        "id": "QWwaGY5JKu5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values from the Segment column\n",
        "df.select(\"Segment\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtw7DpuiKzwt",
        "outputId": "97fd624b-b7ed-4e21-de84-5e8d63219a26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|    Segment|\n",
            "+-----------+\n",
            "|   Consumer|\n",
            "|Home Office|\n",
            "|  Corporate|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we correct the data types of some columns.  \n",
        "As you can see, the columns **\"Order Date\"** and **\"Ship Date\"** were strings but should be converted to dates.  \n",
        "The column **\"Postal Code\"** should be an integer, and **\"Sales\"** should be a double for numerical calculations."
      ],
      "metadata": {
        "id": "9DSP84cbNk55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the types of the columns to their correct types\n",
        "from pyspark.sql.functions import col, to_date\n",
        "\n",
        "# Convert numeric columns\n",
        "df = df.withColumn(\"Sales\", col(\"Sales\").cast(\"double\"))\n",
        "df = df.withColumn(\"Postal Code\", col(\"Postal Code\").cast(\"int\"))\n",
        "\n",
        "# Convert date columns (notice the corrected quotes and format)\n",
        "df = df.withColumn(\"Order Date\", to_date(col(\"Order Date\"), \"dd/MM/yyyy\"))\n",
        "df = df.withColumn(\"Ship Date\", to_date(col(\"Ship Date\"), \"dd/MM/yyyy\"))"
      ],
      "metadata": {
        "id": "p9LF8MaEKvGn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names with their data types\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sySP23EGNq5l",
        "outputId": "fb5d8bc3-376e-4e04-88d5-03a2f7fd1ced"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Row ID', 'int'),\n",
              " ('Order ID', 'string'),\n",
              " ('Order Date', 'date'),\n",
              " ('Ship Date', 'date'),\n",
              " ('Ship Mode', 'string'),\n",
              " ('Customer ID', 'string'),\n",
              " ('Customer Name', 'string'),\n",
              " ('Segment', 'string'),\n",
              " ('Country', 'string'),\n",
              " ('City', 'string'),\n",
              " ('State', 'string'),\n",
              " ('Postal Code', 'int'),\n",
              " ('Region', 'string'),\n",
              " ('Product ID', 'string'),\n",
              " ('Category', 'string'),\n",
              " ('Sub-Category', 'string'),\n",
              " ('Product Name', 'string'),\n",
              " ('Sales', 'double')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check for missing or null values in selected columns\n",
        "def check_nulls(df):\n",
        "    for c in df.columns:\n",
        "        num_null = df.filter((col(c).isNull()) | (col(c) == \"\")).count()\n",
        "        print(f\"The column '{c}' has {num_null} null values.\")\n",
        "\n",
        "check_nulls(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZLETI7cZCJ",
        "outputId": "f1873195-36a6-49f7-b628-6a2b9002ccd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The column 'Row ID' has 0 null values.\n",
            "The column 'Order ID' has 0 null values.\n",
            "The column 'Order Date' has 0 null values.\n",
            "The column 'Ship Date' has 0 null values.\n",
            "The column 'Ship Mode' has 0 null values.\n",
            "The column 'Customer ID' has 0 null values.\n",
            "The column 'Customer Name' has 0 null values.\n",
            "The column 'Segment' has 0 null values.\n",
            "The column 'Country' has 0 null values.\n",
            "The column 'City' has 0 null values.\n",
            "The column 'State' has 0 null values.\n",
            "The column 'Postal Code' has 11 null values.\n",
            "The column 'Region' has 0 null values.\n",
            "The column 'Product ID' has 0 null values.\n",
            "The column 'Category' has 0 null values.\n",
            "The column 'Sub-Category' has 0 null values.\n",
            "The column 'Product Name' has 0 null values.\n",
            "The column 'Sales' has 292 null values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The **Sales** column is very important for our analysis, so we will drop any rows that contain null values in this column.\n",
        "*   On the other hand, the **Postal Code** column is not as critical since we already have information about the city, state, and region. Therefore, we will replace its null values with a placeholder value of 0.\n"
      ],
      "metadata": {
        "id": "Y3lE-8rBf0VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the rows where 'Sales' has null values\n",
        "df = df.na.drop(subset=['Sales'])\n",
        "\n",
        "# Replace null values in 'Postal Code' with a placeholder value of 0\n",
        "df = df.na.fill({'Postal Code': 0})"
      ],
      "metadata": {
        "id": "11iRbzw5f0iN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_nulls(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxx0o_XFgdKa",
        "outputId": "9c9935e2-791c-4ded-cad8-058419d69c56"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The column 'Row ID' has 0 null values.\n",
            "The column 'Order ID' has 0 null values.\n",
            "The column 'Order Date' has 0 null values.\n",
            "The column 'Ship Date' has 0 null values.\n",
            "The column 'Ship Mode' has 0 null values.\n",
            "The column 'Customer ID' has 0 null values.\n",
            "The column 'Customer Name' has 0 null values.\n",
            "The column 'Segment' has 0 null values.\n",
            "The column 'Country' has 0 null values.\n",
            "The column 'City' has 0 null values.\n",
            "The column 'State' has 0 null values.\n",
            "The column 'Postal Code' has 0 null values.\n",
            "The column 'Region' has 0 null values.\n",
            "The column 'Product ID' has 0 null values.\n",
            "The column 'Category' has 0 null values.\n",
            "The column 'Sub-Category' has 0 null values.\n",
            "The column 'Product Name' has 0 null values.\n",
            "The column 'Sales' has 0 null values.\n"
          ]
        }
      ]
    }
  ]
}